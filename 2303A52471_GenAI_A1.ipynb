{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rithima17/GenAI_2303A52471/blob/main/2303A52471_GenAI_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# regression metrices"
      ],
      "metadata": {
        "id": "YweCGpEdUC2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cieaIhOhQA2b"
      },
      "outputs": [],
      "source": [
        "y=[10,20,30,40,50]\n",
        "yp=[10.2,20.5,30.3,40.8,50.6]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without lyb"
      ],
      "metadata": {
        "id": "K_YQ_nkif7OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=(y[i]-yp[i])**2\n",
        "mean_square_error=sum/len(y)\n",
        "print('the mean square error of the above data is: ',mean_square_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htg81I_rQEmH",
        "outputId": "0de03883-b5ab-40ce-8d59-0af5be8f338a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean square error of the above data is:  0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=abs(y[i]-yp[i])\n",
        "mean_abs_error=sum/len(y)\n",
        "print('the mean abs error of the above data is: ',mean_abs_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEiUfHu5QGWG",
        "outputId": "e61e5077-932b-4949-c647-73731d1a19bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean abs error of the above data is:  0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the root mean error of the above data is: ',(mean_square_error**0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNDeUc4pQIAW",
        "outputId": "1a39b774-856b-4eb9-f56e-6cb468ae1b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the root mean error of the above data is:  0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with lyb"
      ],
      "metadata": {
        "id": "3-hMcDNFgE1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "H4ndH-mMQcpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y, yp)\n",
        "print('The Mean Squared Error is:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_hn1xMjQ18f",
        "outputId": "133d39fb-dfee-454a-883d-002ff3c36fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y, yp)\n",
        "print('The Mean Absolute Error is:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNrT8s6fQ-rq",
        "outputId": "6e284382-f3bb-4f0b-f9ff-46a11018ab3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Absolute Error is: 0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = mse**0.5  # RMSE is the square root of MSE\n",
        "print('The Root Mean Squared Error is:', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQdWt0_eRLBU",
        "outputId": "03fd6372-9e45-4a5b-9564-a5e03dd8d957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Root Mean Squared Error is: 0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classification metrices"
      ],
      "metadata": {
        "id": "UzeZFMiWT9Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "yact=[0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2]\n",
        "ypred=[0,0,1,1,2,2,0,1,1,1,2,0,2,1,1,2]"
      ],
      "metadata": {
        "id": "PeqF19kkUlnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without lyb"
      ],
      "metadata": {
        "id": "SkztYDyoUcIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(len(yact)):\n",
        "    l.append([yact[i],ypred[i]])\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80lyDlbkUfXR",
        "outputId": "997c2071-2218-4d31-922e-8453f62d81d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0], [0, 1], [0, 1], [0, 2], [1, 2], [1, 0], [1, 1], [1, 1], [1, 1], [1, 2], [2, 0], [2, 2], [2, 1], [2, 1], [2, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yact_set=list(sorted(set(yact)))\n",
        "yact_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn1-yVFmkR8i",
        "outputId": "0d358b40-2321-4fa1-8963-bbb4d44fa34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=[]\n",
        "for i in yact_set:\n",
        "  temp=[]\n",
        "  for j in yact_set:\n",
        "    temp.append(l.count([i,j]))\n",
        "  cm.append(temp)"
      ],
      "metadata": {
        "id": "oV0xvQTvki_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"confusionmatrix of above data is:\\n\",np.array(cm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXKqWbO1VXW7",
        "outputId": "d59bed0f-2e5a-486a-a750-1554cd794484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusionmatrix of above data is:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_precision_recall_f1(cm):\n",
        "    # Calculate the total number of data points outside of the loop\n",
        "    total = sum(sum(row) for row in cm)\n",
        "    num_classes = len(cm)\n",
        "    precision = [0] * num_classes\n",
        "    recall = [0] * num_classes\n",
        "    f1_score = [0] * num_classes  # Initialize F1-score list\n",
        "    tp_mat = []\n",
        "    fp_mat = []\n",
        "    fn_mat = []\n",
        "    tn_mat = []\n",
        "\n",
        "\n",
        "    for i in range(num_classes):  # Iterate over each class (rows)\n",
        "        # Calculate precision for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fp = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fp += cm[j][i]  # False Positives for class i\n",
        "        if tp + fp != 0:  # Avoid division by zero\n",
        "            precision[i] = tp / (tp + fp)\n",
        "\n",
        "        # Calculate recall for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fn = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fn += cm[i][j]  # False Negatives for class i\n",
        "        if tp + fn != 0:  # Avoid division by zero\n",
        "            recall[i] = tp / (tp + fn)\n",
        "\n",
        "        # Calculate F1-score for class i\n",
        "        if precision[i] + recall[i] != 0:  # Avoid division by zero\n",
        "            f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
        "\n",
        "        tp_mat.append(tp)\n",
        "        fp_mat.append(fp)\n",
        "        fn_mat.append(fn)\n",
        "        tn_mat.append(total - tp - fp - fn)  # Use the total calculated outside the loop\n",
        "\n",
        "    # Return total along with other metrics\n",
        "    return precision, recall, f1_score, tp_mat, fp_mat, fn_mat, tn_mat, total\n",
        "\n",
        "# Assuming 'cm' is defined as in your previous code\n",
        "precision_values, recall_values, f1_values, tp_mat, fp_mat, fn_mat, tn_mat, total = calculate_precision_recall_f1(cm)\n",
        "\n",
        "# Print results for each class\n",
        "for i in range(len(precision_values)):\n",
        "    print(f\"Class {i} - Precision: {precision_values[i]}, Recall: {recall_values[i]}, F1-Score: {f1_values[i]}\")\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"\\nOverall Accuracy: {np.sum(tp_mat)/total}\") # Using the calculated 'total' here\n",
        "print(f\"Overall Precision: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fp_mat))}\")\n",
        "print(f\"Overall Recall: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fn_mat)):.4f}\")\n",
        "print(f\"Overall F1-Score: {np.mean(f1_values)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LGz-aluZMmo",
        "outputId": "60353d5c-2e94-40d3-9f3b-194af8d360cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 - Precision: 0.5, Recall: 0.4, F1-Score: 0.4444444444444445\n",
            "Class 1 - Precision: 0.42857142857142855, Recall: 0.5, F1-Score: 0.4615384615384615\n",
            "Class 2 - Precision: 0.4, Recall: 0.4, F1-Score: 0.4000000000000001\n",
            "\n",
            "Overall Accuracy: 0.4375\n",
            "Overall Precision: 0.4375\n",
            "Overall Recall: 0.4375\n",
            "Overall F1-Score: 0.43532763532763535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with lyb"
      ],
      "metadata": {
        "id": "4eETeXIIUZeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(yact, ypred))\n",
        "\n",
        "# Classification Report (Precision, Recall, F1)\n",
        "print(\"Classification Report:\\n\", classification_report(yact, ypred))\n",
        "\n",
        "# Individual Metrics\n",
        "accuracy = accuracy_score(yact, ypred)\n",
        "precision = precision_score(yact, ypred, average='weighted')\n",
        "recall = recall_score(yact, ypred, average='weighted')\n",
        "f1 = f1_score(yact, ypred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbmiyYfVSTb4",
        "outputId": "c7d91ea1-b3c4-488b-d0e8-4f1d0b6d7075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.40      0.44         5\n",
            "           1       0.43      0.50      0.46         6\n",
            "           2       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.44      0.43      0.44        16\n",
            "weighted avg       0.44      0.44      0.44        16\n",
            "\n",
            "Accuracy: 0.4375\n",
            "Precision: 0.4419642857142857\n",
            "Recall: 0.4375\n",
            "F1-Score: 0.43696581196581197\n"
          ]
        }
      ]
    }
  ]
}